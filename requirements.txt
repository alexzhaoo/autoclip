
torch

# FlashAttention (install manually with build flags)
# Run: pip install flash-attn==2.8.3 --no-build-isolation --use-pep517
# flash-attn
nvidia-cublas-cu12
# Ensure cuDNN 9.1+ is present; CTranslate2 may dlopen libcudnn_ops.so.9.1*
nvidia-cudnn-cu12>=9.1,<10
# Core dependencies
opencv-python>=4.9.0.80
diffusers>=0.31.0
# Newer diffusers PEFT loader expects `transformers.modeling_layers`.
# Keep this reasonably modern; avoid tight upper-bounds that break over time.
transformers>=4.52,<4.53
tokenizers>=0.20.3
accelerate>=1.1.1
tqdm
imageio[ffmpeg]
easydict
ftfy
dashscope
imageio-ffmpeg
numpy>=1.23.5,<2
openai>=1.0.0
python-dotenv>=1.0.0
yt-dlp>=2023.1.0

# Video processing
mediapipe==0.10.21
moviepy>=1.0.3
pysubs2>=1.6.0
pysrt>=1.1.2


# Audio processing
faster-whisper>=0.9.0
pydub>=0.25.0
elevenlabs>=0.2.0

# Text processing
nltk>=3.8.0

# AI/ML for B-roll generation
# (Already required above; keep here only for readability)
pillow>=10.0.0
diffusers[torch]>=0.18.0

# Web requests
requests>=2.31.0

# Vast.ai SDK
vastai-sdk>=0.1.0

# Additional utilities
pathlib2>=2.3.0
dataclasses>=0.6; python_version<"3.7"
decord
librosa
peft

# LightX2V Wan2.2 T2V 4-step distill backend
# (Installed from GitHub; used by video_gen.py)
lightx2v @ git+https://github.com/ModelTC/LightX2V.git

# Hugging Face download tooling used by setup_wan.sh
# Keep <1.0 for compatibility with transformers/tokenizers currently pinned above.
huggingface_hub<1.0
hf_transfer

# Common model file format dependency (often pulled transitively, but keep explicit)
safetensors>=0.4.0
